---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Adriana Banchs, amb8722

### Introduction 

The Socio-Economic Country Profiles data set will be analyzed in this project. This data set was found on Kaggle, and it contains different measures for countries relating to the economy, health, employment, demographics, and more. Some of the variables included in this data set are the region, population, GDP, percent of labor force unemployed, age expectancy, and infant mortality rate. There are 12 variables in the final data set used and 229 countries. The binary variable of hemisphere was created for this data set, and there are 172 countries in the Eastern hemisphere and 57 countries in the Western hemisphere.

```{R}
library(tidyverse)

profile <- read_csv("profile.csv")

profile %>% separate(`Labour force participation (female/male pop. %)`, into=c("Laborforce_participation_women_%","Laborforce_participation_men_%"), sep="/") %>%
  separate(`Life expectancy at birth (females/males, years)`, into=c("Lifeexpectancy_females_yrs", "Lifeexpectancy_males_yrs"), sep="/") %>% separate(`Population age distribution (0-14 / 60+ years, %)`, into=c("Pop_age_dist_0-14yrs_%", "Pop_age_dist_60+yrs_%")) %>% separate(`Pop. using improved drinking water (urban/rural, %)`, into=c("Pop_improveddrinkingwater_urban_%", "Pop_improveddrinkingwater_rural_%")) -> profile

profile %>% rename(pop=`Population in thousands (2017)`, GDP=`GDP per capita (current US$)`, percent_unemployement=`Unemployment (% of labour force)`,  lifeex.f=Lifeexpectancy_females_yrs, lifeex.m=Lifeexpectancy_males_yrs, infmort=`Infant mortality rate (per 1000 live births`, physicians=`Health: Physicians (per 1000 pop.)`,seatswomen=`Seats held by women in national parliaments %`, co2=`CO2 emission estimates (million tons/tons per capita)`, pop_dens='Population density (per km2, 2017)', sa='Surface area (km2)', health_expenditure='Health: Total expenditure (% of GDP)') -> profile

profile %>% na_if("...") %>% na_if("-99") %>% na_if("~0.0") -> profile

profile %>% select(1:5,9,16,29,30,35,37,48) -> profileclean
profileclean %>% mutate_at(3:12, as.numeric) -> profileclean
profileclean %>% mutate(Hemisphere= ifelse(Region=="SouthernAsia"| Region=="South-easternAsia"| Region=="EasternAsia"| Region=="CentralAsia"| Region=="WesternAsia"| Region=="MiddleAfrica"| Region== "NorthernAfrica"| Region=="WesternAfrica"| Region=="EasternAfrica"| Region=="SouthernAfrica"| Region=="Oceania"| Region=="WesternEurope"| Region=="EasternEurope"| Region=="NorthernEurope" | Region=="SouthernEurope"| Region=="Polynesia" | Region=="Melanasia" | Region=="Micronesia"| Region=="Oceania", "Eastern", "Western")) -> profileclean

profileclean %>% group_by(Hemisphere) %>% summarize(n=n())
profileclean %>% head
```

### Cluster Analysis

```{R}
library(cluster)
clust_prof<-profileclean %>% select(3:12) %>% na.omit

sil_width<-vector()
for(i in 2:10){  
  pam_fit2 <- pam(clust_prof, k = i)  
  sil_width[i] <- pam_fit2$silinfo$avg.width  
}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)

pam_profile <- clust_prof %>% pam(k=2)
pam_profile

library(GGally)
pam_ggpairs<-clust_prof%>%mutate(cluster=as.factor(pam_profile$clustering))

pam_ggpairs %>% ggpairs(cols=1:10, aes(color=cluster))
```

To perform this cluster analysis, the number of clusters was chosen based on the highest average silhouette width After plotting the silhouette widths for a k of 2 through 10, a k of 2 was chosen, since this gives the highest silhouette width of about 0.95. This value suggests that the clusters provide a strong structure. Based on the pam clustering output, it can be seen that the two medoids are most similar in their life expectancy variables, but most different in their percent unemployment, surface area, population, and CO2 emissions. Based on the ggpairs plot created, the clusters seem to overlap with most variables. However, there appears to be a larger difference in the surface area variable, with cluster 1 having a lower surface area and cluster 2 having a higher surface area. Additionally, the GDP of cluster 1 tends to be low, but the GDP of cluster 2 is spread out across low and high vaues. It is also evident of the high overlap in the life expectancy variables.
    
    
### Dimensionality Reduction with PCA

```{R}
prof_numeric <- profileclean %>% select(is.numeric) %>% na.omit
princomp(prof_numeric, cor=T) -> pca1
summary(pca1, loadings=T)

pca1$scores %>% as.data.frame() %>% bind_cols(prof_numeric) %>% select(PCA1=1, PCA2=2) ->pca_data
pca_data %>% ggplot(aes(PCA1, PCA2)) + geom_point(size=4)
```

After running the principal component analysis, it can be seen above that the first principal component accounts for only about 40% of the variance. The first 2 principal components account for 62% of the variability, and the first 5 principal components account for 88% of variability. A high PCA1 means that a country has a low infant mortality rate and a high population density, GDP, life expectancy for women and men, and number of physicians per 1000 people. A high PCA2 means that a country has a high surface area, population and CO2 emissions, and a low percent of unemployment.

From the scatterplot generated with PCA1 and PCA2, it can be observed that most countries have a low PCA2, although there are a few outliers. The countries are spread out across PCA1 scores however.

###  Linear Classifier

```{R}
profileclean %>% select(13, 3:12) %>% na.omit -> classdat

logis_fit <- glm(Hemisphere=="Eastern" ~ ., data=classdat, family="binomial")
prob_reg2 <- predict(logis_fit, type = "response")
class_diag(prob_reg2,classdat$Hemisphere, positive="Eastern")

y <- classdat$Hemisphere
y_hat <- ifelse(prob_reg2>.5, "Eastern", "Western") 
table(actual = y, predicted = y_hat) %>% addmargins
```

```{R}
set.seed(322)
k=10

data<-sample_frac(classdat)
folds <- rep(1:k, length.out=nrow(data))

diags<-NULL

i=1
for(i in 1:k){
train<-data[folds!=i,] 
test<-data[folds==i,] 
truth<-test$Hemisphere

fit <- glm(Hemisphere=="Eastern" ~  ., data=train, family = "binomial")

probs <- predict(fit, newdata=test, type = "response")

diags<-rbind(diags,class_diag(probs,truth,positive = "Eastern")) 
}

summarize_all(diags,mean)
```

First, logistic classification was performed to predict whether the countries in the data set are in the Western or Eastern hemisphere, using all of the numeric variables. The AUC for the linear classification is a 0.9167, which means this model is very good at making accurate predictions. A confusion matrix was then made to show how many countries were being classified correctly and incorrectly. For example, out of all of the countries in the Eastern hemisphere, about 96% of them were classified correctly. However, out of all of the countries in the Western hemisphere, only about 56% of them were classified correctly. The model does a much better job correctly classifying the Western countries.

Then, a k-fold cross validation was performed to test how well this model performs when predicting out of a sample. The AUC for the cross validation dropped down to a 0.824, which suggests that there is overfitting in the logistic classification model.

### Non-Parametric Classifier

```{R}
library(caret)

knn_fit <- knn3(Hemisphere=="Eastern" ~ ., data=classdat)
prob_knn <- predict(knn_fit, newdata = classdat)[,2]
class_diag(prob_knn, truth = classdat$Hemisphere, positive="Eastern")

y_hat_knn <- predict(knn_fit,classdat)
table(truth= factor(classdat$Hemisphere=="Eastern", levels=c("TRUE","FALSE")),
      prediction= factor(y_hat_knn[,1]>.5, levels=c("TRUE","FALSE"))) %>% addmargins

```

```{R}
set.seed(322)
k=10

data<-sample_frac(classdat)
folds <- rep(1:k, length.out=nrow(data))

diags<-NULL

i=1
for(i in 1:k){
train<-data[folds!=i,] 
test<-data[folds==i,] 
truth<-test$Hemisphere

fit <- knn3(Hemisphere=="Eastern" ~ ., data=train)

probs<-predict(fit,newdata = test)[,2]

diags<-rbind(diags,class_diag(probs,truth, positive = "Eastern")) }

summarize_all(diags,mean)
```

In this section, k-nearest-neighbor was used to predict the hemisphere based on all of the numeric variables. The AUC was calculated to be about 0.83, which means this model is decent at predicting the hemisphere of the different countries, but not as good as the logistic model. Then, a cross validation was run to test the model's predictions with a sample from the data set. The AUC for the cross validation is 0.47, which means there is a lot of overfitting, and the model predicts very poorly out-of-sample. This model performs much worse on new data than the logistic model.


### Regression/Numeric Prediction

```{R}
fit<-lm(physicians~.,data=prof_numeric)
yhat<-predict(fit)

mean((prof_numeric$physicians-yhat)^2)

```

```{R}
set.seed(1234)
k=5
data<-prof_numeric[sample(nrow(prof_numeric)),]
folds<-cut(seq(1:nrow(prof_numeric)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
  train<-data[folds!=i,]
  test<-data[folds==i,]
  fit<-lm(physicians~.,data=train)
  yhat<-predict(fit,newdata=test)
  diags<-mean((test$physicians-yhat)^2) 
}
mean(diags)
```

In this part of the project, a linear regression model was made to predict how many physicians a country has per 1000 people. The mean squared error (MSE) for the entire dataset was calculated to be 0.98. When a cross validation was run on this model, the MSE was calculated to be about 0.96. Since the MSE for the cross validation is less than the MSE for the entire data set, there is no evidence of overfitting.

### Python 

```{R}
library(reticulate)
use_python("/usr/bin/python3")
```

```{python}
py_data = r.profileclean
py_data['GDP']
```

```{R}
py$py_data %>% glimpse()
py$py_data %>% data.frame() %>% select("GDP")
```

In this section, the 'profileclean' data frame was read into python and named as a NumPy array. Then, only the GDP values for all of the countries were printed out. After that, the new data frame created in Python was read into R Studio as a list, so it was converted into a data frame, and only the GDP values were selected.




